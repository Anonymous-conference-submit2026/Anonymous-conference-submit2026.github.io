<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>BoundaryDPT: Project Overview</title>

<style>
    body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
        margin: 0;
        padding: 0;
        color: #222;
        background: #fafafa;
        line-height: 1.6;
    }

    header {
        background: #111;
        color: white;
        padding: 40px 20px;
        text-align: center;
    }

    header h1 {
        margin: 0;
        font-size: 2rem;
        font-weight: 700;
    }

    section {
        padding: 30px 20px;
        max-width: 900px;
        margin: auto;
    }

    h2 {
        border-left: 4px solid #0070f3;
        padding-left: 10px;
        margin-top: 40px;
        font-size: 1.6rem;
        display: flex;
        align-items: center;
        gap: 8px;
    }

    h2 .icon {
        font-size: 1.5rem;
    }

    .img-block {
        margin: 20px 0;
        text-align: center;
    }

    img {
        width: 100%;
        max-width: 850px;
        border-radius: 6px;
        background: white;
        box-shadow: 0 0 10px rgba(0,0,0,0.05);
    }
    .img-title {
        font-size: 1.1rem;       /* ÂéüÊú¨ÂèØËÆæ‰∏∫ 1.0remÔºåÂèØÊ†πÊçÆÈúÄË¶ÅË∞ÉÂ§ß */
        font-weight: 600;
        margin-bottom: 8px;
        text-align: center;
        color: #333;
    }
    footer {
        margin-top: 50px;
        padding: 20px;
        text-align: center;
        color: #666;
    }

    @media (max-width: 600px) {
        h1 { font-size: 1.7rem; }
        h2 { font-size: 1.3rem; }
    }
</style>

</head>

<body>

<header>
    <h1>BoundaryDPT: Pushing the Boundaries of Depth Pruning for Vision Transformers</h1>
</header>

<!-- ===================== 1. OVERVIEW ===================== -->
<section id="overview">
    <h2><span class="icon">üìò</span>1. Overview</h2>
    <div class="img-block">
        <div class="img-title"><strong>Overview of BoundaryDPT Framework</strong></div>
        <img src="fig/overview.svg" alt="Overview" />
    </div>
    <p>
        <strong>BoundaryDPT</strong> is a new depth pruning framework for Vision Transformers (ViTs) that 
        significantly extends the efficiency‚Äìaccuracy frontier beyond previous pruning approaches. 
        While most ViT compression techniques focus on width pruning or suffer accuracy collapse 
        when removing entire layers, BoundaryDPT provides a principled, heterogeneity solution 
        that jointly prunes <strong>attention layers</strong> and <strong>activation function layers</strong> (the first method 
        to exploit activation‚Äëlayer redundancy in ViTs.)
    </p>

    <p>
        Through a three‚Äëstage pipeline that integrates a Model Accuracy Predictor (MAP), 
        training‚Äëbased layer selection, finetuning and post‚Äëpruning MLP merging, BoundaryDPT resolves 
        dimension‚Äëmismatch problems and fully unlocks depth pruning‚Äôs superior acceleration potential. 
        Experiments on ImageNet‚Äë1K, CIFAR‚Äë100, and ADE20K show that BoundaryDPT delivers 
        <strong>lossless or near‚Äëlossless accuracy</strong> while achieving substantially 
        <strong>higher speedups</strong> than previous depth pruning or token pruning methods.
    </p>

    <p>
        Building on this foundation, <strong>BoundaryDPT+</strong> integrates depth pruning with width pruning, 
        achieving state‚Äëof‚Äëthe‚Äëart results in <em>extreme</em> ViT compression. 
        For example, BoundaryDPT+ improves the speedup of the popular 
        Isomorphic-Pruning‚Äë2.6G configuration from <strong>4.24√ó to 5.19√ó</strong> while 
        maintaining (and even improving) accuracy‚Äîestablishing a new benchmark for efficient ViT deployment.
    </p>

    <p>
        BoundaryDPT reveals and leverages previously untapped structural redundancy in ViTs, 
        offering a scalable compression strategy for real‚Äëworld acceleration.
    </p>

    <div class="img-block">
        <div class="img-title"><strong>Our Method Push the Pareto Frontier of ViT Compression</strong></div>
        <img src="fig/Pareto.svg" alt="Pareto Frontier" />
    </div>
</section>

<!-- ===================== 2. MOTIVATION ===================== -->
<section id="motivation">
    <h2><span class="icon">üéØ</span>2. Motivation</h2>
    <p>
    <strong>Depth pruning and its limitation.</strong> Depth pruning removes entire ViT layers and offers much higher speedups than width pruning under the same sparsity. However, aggressive layer removal often causes severe accuracy degradation. As a result, depth‚Äìwidth hybrid methods are also constrained by the weakness of depth pruning.
    </p>
    <div class="img-block">
         <div class="img-title"><strong>Our Method Push the Pareto Frontier of ViT Compression</strong></div>
        <img src="fig/depth_vs_width_pruning.svg" alt="Depth vs Width" />
    </div>



    <p>
    <strong>Joint depth pruning matters.</strong> Contrary to the common belief that accuracy collapse comes from coarse pruning granularity, our analysis shows the real issue is the lack of <em>joint</em> pruning that accounts for cross‚Äëlayer heterogeneity. Pruning only attention layers or only activation layers causes large accuracy drops, while pruning them jointly maintains accuracy and efficiency.
    </p>


    <div class="img-block">
        <img src="fig/vit_latency.svg" alt="Layer Latency Distribution" />
    </div>
    <p>

    <strong>Dimension mismatch hinders joint pruning.</strong> Linear layers and attention layers dominate ViT latency, so pruning them together is essential. Yet, removing them independently breaks tensor shapes and leads to dimension mismatch (e.g., FFN linear layers no longer align with surrounding attention blocks), making joint depth‚Äëpruned models invalid.
    </p>

    <div class="img-block">
        <img src="fig/dim_mismatch.svg" alt="Dimension Mismatch" />
    </div>
</section>

<!-- ===================== 3. KEY OBSERVATIONS ===================== -->
<section id="key-observations">
    <h2><span class="icon">üîç</span>3. Key Observations</h2>

    <p>
        Our analysis reveals two hidden but fundamental challenges inside ViTs:
    </p>

    <h3>‚Ä¢ Gradient Disparity</h3>
    <p>
        Activation layers and attention layers have very different gradient magnitudes, which causes 
        gradient-based pruning methods to be heavily biased.
    </p>

    <div class="img-block">
        <img src="fig/Gradient_Disparity.svg" alt="Gradient Disparity" />
    </div>

    <h3>‚Ä¢ Recovery Asymmetry</h3>
    <p>
        Activation-layer pruning initially produces large accuracy drops but recovers extremely fast. 
        Attention-layer pruning behaves in the opposite way.
    </p>

    <div class="img-block">
        <img src="fig/Recovery_Asymmetry.svg" alt="Recovery Asymmetry" />
    </div>

</section>

<!-- ===================== 4. METHOD ===================== -->
<section id="method">
    <h2><span class="icon">üß©</span>4. Method: BoundaryDPT</h2>

    <p>
        BoundaryDPT is a three-stage depth pruning framework that addresses gradient disparity, 
        recovery asymmetry, and dimension mismatch. The pipeline consists of:
    </p>

    <ul>
        <li><b>MAP-based pruning ratio determination</b> ‚Äî predicts accuracy for different combinations of pruned attention/activation layers.</li>
        <li><b>Training-based redundant layer identification</b> ‚Äî avoids biased importance ranking across different layer types.</li>
        <li><b>Activation-layer removal + MLP merging</b> ‚Äî safely reduces depth without breaking tensor shapes.</li>
    </ul>


    <div class="img-block">
        <img src="fig/pipeline.svg" alt="Pipeline" />
    </div>

</section>

<!-- ===================== 5. EXPERIMENTAL RESULTS ===================== -->
<section id="results">
    <h2><span class="icon">üìà</span>5. Experimental Results</h2>

    <p>
        BoundaryDPT achieves state-of-the-art depth pruning results on DeiT-S and DeiT-B, and when 
        combined with width pruning (BoundaryDPT+), it sets new benchmarks for extreme ViT compression.
    </p>

    <div class="img-block">
        <img src="fig/speedup_accuracy_comparison_combined.svg" alt="Speedup vs Accuracy Combined" />
    </div>

    <div class="img-block">
        <img src="fig/speedup_acc_curve_small.svg" alt="Speedup Accuracy Curve Small" />
    </div>

    <div class="img-block">
        <img src="fig/speedup_acc_curve_base.svg" alt="Speedup Accuracy Curve Base" />
    </div>

    <p>
        BoundaryDPT consistently improves the robustness and efficiency of ViT depth pruning, 
        achieving Pareto-optimal tradeoffs between accuracy and speed.
    </p>

</section>

<footer>
    ¬© 2025 BoundaryDPT Project
</footer>

</body>
</html>